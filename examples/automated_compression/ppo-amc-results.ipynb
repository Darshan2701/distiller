{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using Clipped PPO for Automated Model Compression\n",
    "\n",
    "\n",
    "Continuing on the work of [AMC](https://arxiv.org/abs/1802.03494) we replace DDPG with Clipped PPO.\n",
    "\n",
    "Results are interesting and encouraging as there is learning.  However, this is less sample-efficient compared to DDPG, and therefore takes longer.\n",
    "\n",
    "We search for a 50%-MACs-constrained (FLOPs-constrained) Plain20.  From Greedy Search algorithm we know that there exists a 50%-MACs-constrained Plain20 that can provide Top1=90%.  The current fine-tuned Plain20 model from our PPO experiments has a Top1=89%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment setup\n",
    "\n",
    "\n",
    "### Clipped PPO configuration\n",
    "\n",
    "### Distiller Clipped PPO AMC experiments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook code\n",
    "\n",
    "Skip this part - it is necessary only for creating the diagrams.  You may also toggle the code-view button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off code view\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib \n",
    "import csv\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interactive, interact, Layout\n",
    "import matplotlib.pylab as pylab\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import animation, rc\n",
    "\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (15, 7),\n",
    "          'axes.labelsize': 'x-large',\n",
    "          'axes.titlesize':'xx-large',\n",
    "          'xtick.labelsize':'x-large',\n",
    "          'ytick.labelsize':'x-large'}\n",
    "pylab.rcParams.update(params)\n",
    "\n",
    "#plt.style.use('seaborn') # pretty matplotlib plots\n",
    "\n",
    "\n",
    "def to_percent(y, position):\n",
    "    # Ignore the passed in position. This has the effect of scaling the default\n",
    "    # tick locations.\n",
    "    if y < 1:\n",
    "        y = 100 * y\n",
    "    s = \"{:.1f}\".format(y)\n",
    "\n",
    "    # The percent symbol needs escaping in latex\n",
    "    if matplotlib.rcParams['text.usetex'] is True:\n",
    "        return s + r'$\\%$'\n",
    "    else:\n",
    "        return s + '%'\n",
    "    \n",
    "# Widen the cells to get entire rows in the screen.\n",
    "from IPython.core.display import display, HTML\n",
    "#display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import json\n",
    "\n",
    "def plot_layer_compute_densities(df, idx, ax=None, color=None):\n",
    "    if ax is None:\n",
    "        plt.figure()\n",
    "        ax = plt\n",
    "    \n",
    "    record = df.iloc[idx]\n",
    "    net_performance = json.loads(record[\"performance\"])\n",
    "    ax.bar(range(len(net_performance)), list(net_performance.values()), color=color, align='center')\n",
    "    ax.set_title(\"Ep:{} - Top1:{:.1f}%\\nMACs:{:.1f}%\".format(record['episode'], \n",
    "                                                             record['top1'], \n",
    "                                                             record['normalized_macs']))\n",
    "    #ax.set_xticks(range(len(net_performance)), list(net_performance.keys()))\n",
    "\n",
    "\n",
    "def plot_action_history(df, idx, action_type='action_history', ax=None, color=None):\n",
    "    if ax is None:\n",
    "        plt.figure()\n",
    "        ax = plt\n",
    "    \n",
    "    record = df.iloc[idx]\n",
    "    layer_sparsities = json.loads(record[action_type])\n",
    "    #layer_sparsities = record[action_type]\n",
    "    #layer_sparsities = layer_sparsities[1:-1].split(\",\")\n",
    "    layer_densities = [1.- float(sparsity) for sparsity in layer_sparsities]\n",
    "    ax.bar(range(len(layer_densities)), layer_densities, color=color)\n",
    "    ax.set_title(\"Ep:{} - Top1:{:.1f}%\\nMACs:{:.1f}%\".format(record['episode'], \n",
    "                                                             record['top1'], \n",
    "                                                             record['normalized_macs']))\n",
    "\n",
    "\n",
    "\n",
    "def smooth(data, win_size):\n",
    "    if not win_size:\n",
    "        return data\n",
    "    win_size = max(0, win_size)\n",
    "    return [np.mean(data[max(0, i-win_size):i]) for i in range(len(data))]\n",
    "\n",
    "\n",
    "def plot_performance(title, dfs, alpha, window_size, top1, macs, params, reward, start=0, end=-1, plot_type='error'):\n",
    "    plot_kwargs = {\"figsize\":(15,7), \"lw\": 1, \"alpha\": alpha, \"title\": title, \"grid\": True}\n",
    "    smooth_kwargs = {\"lw\": 2 if window_size > 0 else 1, \"legend\": True, \"grid\": True}\n",
    "    \n",
    "    if not isinstance(dfs, list):\n",
    "        dfs = [dfs]\n",
    "    # Apply zoom\n",
    "    df_end = min([len(df) for df in dfs])\n",
    "    if end > 0:\n",
    "        #df_end = min(df_end, end)\n",
    "        end = min(df_end, end)\n",
    "    else:\n",
    "        end = df_end\n",
    "    print(end)\n",
    "    #dfs = [df[:df_end].copy() for df in dfs] \n",
    "    dfs = [df for df in dfs] \n",
    "    df = dfs[0]\n",
    "    left_axs, right_axs = [], []\n",
    "    \n",
    "    if macs:\n",
    "        ax = df['normalized_macs'][start:end].plot(**plot_kwargs, color=\"r\")\n",
    "        left_axs.append((ax, \"MACs\"))\n",
    "        #ax.set(xlabel=\"Episode\", ylabel=\"(%)\")\n",
    "        #ax.set_ylim([0,100])\n",
    "        df['smooth_normalized_macs'] = smooth(df['normalized_macs'], window_size)\n",
    "        df['smooth_normalized_macs'][start:end].plot(**smooth_kwargs, color=\"r\")\n",
    "\n",
    "    if top1:\n",
    "        for df in dfs:\n",
    "            df['smooth_top1'] = smooth(df['top1'], window_size)\n",
    "        \n",
    "        if len(dfs) > 1:\n",
    "            plot_kwargs['alpha'] = 1.0\n",
    "            plot_kwargs['legend'] = True\n",
    "            if plot_type == 'error':\n",
    "                top1_len = min([len(df) for df in dfs])\n",
    "                dfs = [df[:top1_len] for df in dfs]\n",
    "                dfs_top1 = [df['smooth_top1'] for df in dfs]\n",
    "                dfs_top1_dp = pd.DataFrame(dfs_top1)\n",
    "                top1_min = dfs_top1_dp.min(axis=0)\n",
    "                top1_max = dfs_top1_dp.max(axis=0)\n",
    "                top1_mean = dfs_top1_dp.mean(axis=0)\n",
    "                \n",
    "                display_mean = False\n",
    "                if display_mean:\n",
    "                    ax = top1_mean.plot(**plot_kwargs, color=\"b\")\n",
    "                \n",
    "                for p in dfs_top1:\n",
    "                    ax = p[start:end].plot(**plot_kwargs)\n",
    "                if display_mean:\n",
    "                    ax.legend(['mean'] + [str(i+1) for i in range(len(dfs_top1))])\n",
    "                else:\n",
    "                    ax.legend([str(i+1) for i in range(len(dfs_top1))])\n",
    "                ax.set(xlabel=\"Episode\", ylabel=\"(%)\")            \n",
    "                ax.fill_between(range(len(top1_min)), top1_max, top1_min, color=\"b\", alpha=0.3)\n",
    "\n",
    "                left_axs.append((ax, \"Top1\"))\n",
    "            else:\n",
    "                assert plot_type == 'compare'\n",
    "                dfs_top1 = [df['smooth_top1'] for df in dfs]\n",
    "                for p in dfs_top1:\n",
    "                    #ax = p[start:end].plot(**plot_kwargs)\n",
    "                    ax = p[start:].plot(**plot_kwargs)\n",
    "                ax.legend([str(i+1) for i in range(len(dfs_top1))])\n",
    "                left_axs.append((ax, \"Top1\"))\n",
    "        else:\n",
    "            ax = df['top1'][start:end].plot(**plot_kwargs, color=\"b\")\n",
    "            left_axs.append((ax, \"Top1\"))\n",
    "            #ax.set(xlabel=\"Episode\", ylabel=\"(%)\")\n",
    "            df['smooth_top1'][start:end].plot(**smooth_kwargs, color=\"b\")\n",
    "            \n",
    "    if params:\n",
    "        ax = df['normalized_nnz'][start:end].plot(**plot_kwargs, color=\"black\")\n",
    "        ax.set(xlabel=\"Episode\", ylabel=\"(%)\")\n",
    "        df['smooth_normalized_nnz'] = smooth(df['normalized_nnz'], window_size)\n",
    "        df['smooth_normalized_nnz'][start:end].plot(**smooth_kwargs, color=\"black\")        \n",
    "\n",
    "    if reward:\n",
    "        ax = df['reward'][start:end].plot(**plot_kwargs, secondary_y=True, color=\"g\")\n",
    "        ax.set(xlabel=\"Episode\", ylabel=\"Reward\")\n",
    "        df['smooth_reward'] = smooth(df['reward'], window_size)\n",
    "        df['smooth_reward'][start:end].plot(**smooth_kwargs, secondary_y=True, color=\"g\")    \n",
    "    #ax.set_ylim([0,100])\n",
    "    #ax.grid(True, which='minor', axis='x', alpha=0.3)\n",
    "    plt.xlabel(\"Episode\")\n",
    "    \n",
    "    # The left axis might contain multiple ylabels\n",
    "    if left_axs:\n",
    "        # Pick an arbitrary axis \n",
    "        ax = left_axs[0][0]\n",
    "        # Collect all of the labels\n",
    "        ylabel = \" / \".join([ax[1] for ax in left_axs]) #left_axs[0][1]\n",
    "        ax.set(ylabel=ylabel)\n",
    "\n",
    "\n",
    "        \n",
    "def plot_2d_embeddings(top1, normalized_macs):\n",
    "    plt.figure(figsize=(15,7))        \n",
    "    plt.title('Projection of Discovered Networks ({})'.format(len(top1)))     \n",
    "    plt.xlabel('Normalized MACs')\n",
    "    plt.ylabel('Top1 Accuracy')\n",
    "\n",
    "    # Create the formatter using the function to_percent. This multiplies all the\n",
    "    # default labels by 100, making them all percentages\n",
    "    formatter = FuncFormatter(to_percent)\n",
    "\n",
    "    # Set the formatter\n",
    "    plt.gca().yaxis.set_major_formatter(formatter)\n",
    "    plt.gca().xaxis.set_major_formatter(formatter)\n",
    "\n",
    "    # Use color gradients to show the \"age\" of the network:\n",
    "    # Lighter networks were discovered earlier than darker ones.\n",
    "    color_grad = [str(1-i/len(top1)) for i in range(len(top1))]\n",
    "    plt.scatter(normalized_macs, top1, color=color_grad, s=80, edgecolors='gray');\n",
    "\n",
    "    \n",
    "INTERVAL = 30 # Animation speed\n",
    "WINDOW = 20\n",
    "\n",
    "font = {'family': 'serif',\n",
    "        'color':  'darkred',\n",
    "        'weight': 'normal',\n",
    "        'alpha': 0.50,\n",
    "        'size': 32,\n",
    "        }\n",
    "\n",
    "# Based on these two helpful example code: \n",
    "# https://stackoverflow.com/questions/9401658/how-to-animate-a-scatter-plot\n",
    "# http://louistiao.me/posts/notebooks/embedding-matplotlib-animations-in-jupyter-notebooks/.\n",
    "# Specifically, the use of IPython.display is missing from the first example, but most of the animation code\n",
    "# leverages code from there.\n",
    "class AnimatedScatter(object):\n",
    "    \"\"\"An animated scatter plot using matplotlib.animations.FuncAnimation.\"\"\"\n",
    "    def __init__(self, xdata, ydata):\n",
    "        assert len(xdata) == len(ydata)\n",
    "        self.numpoints = len(xdata)\n",
    "        self.xdata = xdata\n",
    "        self.ydata = ydata\n",
    "        self.stream = self.data_stream()\n",
    "\n",
    "        # Setup the figure and axes...\n",
    "        self.fig, self.ax = plt.subplots(figsize=(15,7))\n",
    "        # Then setup FuncAnimation.\n",
    "        self.ani = animation.FuncAnimation(self.fig, self.update, interval=INTERVAL,\n",
    "                                           frames=self.numpoints-2, \n",
    "                                           init_func=self.setup_plot, blit=True)\n",
    "\n",
    "    def setup_plot(self):\n",
    "        \"\"\"Initialize drawing of the scatter plot.\"\"\"\n",
    "        x, y, s, c = next(self.stream)\n",
    "        #self.annot = self.ax.annotate(\"txt\", (10, 10))\n",
    "        self.scat = self.ax.scatter(x, y, c=c, s=s, animated=False)\n",
    "        self.scat.set_edgecolors('gray')\n",
    "        self.scat.set_cmap('gray')\n",
    "        self.width = max(self.xdata) - min(self.xdata) + 4\n",
    "        self.height = max(self.ydata) - min(self.ydata) + 4\n",
    "        self.ax.axis([min(self.xdata)-2, max(self.xdata)+2, \n",
    "                      min(self.ydata)-2, max(self.ydata)+2])\n",
    "        \n",
    "        self.annot = self.ax.text(min(self.xdata) + self.width/2, self.height/2, \n",
    "                     \"\", fontdict=font)\n",
    "        # For FuncAnimation's sake, we need to return the artist we'll be using\n",
    "        # Note that it expects a sequence of artists, thus the trailing comma.\n",
    "        return self.scat, \n",
    "\n",
    "    def data_stream(self):\n",
    "        numpoints = 0#len(self.xdata)\n",
    "        colors = []\n",
    "        xxx = 0\n",
    "        while True:\n",
    "            numpoints += 1\n",
    "            win_len = min(WINDOW, numpoints)\n",
    "            data = np.ndarray((4, win_len))\n",
    "            start = max(0,numpoints-WINDOW-1)\n",
    "            data[0, :] = self.xdata[start:start+win_len]\n",
    "            data[1, :] = self.ydata[start:start+win_len]\n",
    "            data[2, :] = [70] * win_len  # point size\n",
    "            #data[3, :] = [np.random.random() for p in range(numpoints)]  # color\n",
    "            # The color of the points is a gradient with larger values for \"younger\" points.\n",
    "            # At each new frame we show one more point, and \"age\" each existing point by incrementaly  \n",
    "            # reducing its color gradient.\n",
    "            data[3, :] = [(1-i/(win_len+1)) for i in range(win_len)] \n",
    "            yield data\n",
    "\n",
    "    def update(self, i):      \n",
    "        \"\"\"Update the scatter plot.\"\"\"\n",
    "        data = next(self.stream)\n",
    "        self.annot.set_text(i)\n",
    "        i = i % len(data)\n",
    "            \n",
    "        # Set x and y data\n",
    "        xy = [(data[0,i], data[1,i]) for i in range(len(data[0,:]))]\n",
    "        self.scat.set_offsets(xy)\n",
    "        \n",
    "        # Set colors\n",
    "        self.scat.set_array(data[3])\n",
    "        \n",
    "        # We need to return the updated artist for FuncAnimation to draw..\n",
    "        # Note that it expects a sequence of artists, thus the trailing comma.\n",
    "        return self.scat, self.annot\n",
    "\n",
    "    def show(self):\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Results\n",
    "\n",
    "Below I present the results of a single execution.  There is a substantial variance between the experiment executions, but most conclude similarly to this experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the results log files\n",
    "\n",
    "The code below reads the log file of your selected experiment.  To change the path to the file you will need to open the code cell and change its content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 150)\n",
    "fpath = \"../classifier_compression/logs/{}/amc.csv\"\n",
    "\n",
    "fname = \"sample_logs/clipped_ppo/macs_constrained_clipped-ppo.amc.csv\"\n",
    "fname = \"../classifier_compression/logs_stash/resnet56-amc___2019.02.01-053412/amc.csv\"\n",
    "#fname = \"../classifier_compression/logs_stash/plain20-amc-random-2___2019.02.06-063954/amc.csv\"\n",
    "#fname = fpath.format(\"plain20-amc-ft_freq_1___2019.03.06-141637\")\n",
    "fname = fpath.format(\"2019.05.02-170638\")\n",
    "fname = fpath.format(\"2019.05.07-225658\") # fm reconstruction\n",
    "fname = fpath.format(\"2019.05.12-145714\") # random L1- looks optimistic\n",
    "fname = fpath.format(\"2019.05.12-173207\") \n",
    "fname = fpath.format(\"2019.05.12-225134\") # reconstruction w/o FT (89.3)\n",
    "#  time python3 compress_classifier.py --arch=plain20_cifar ../../../data.cifar --resume=checkpoint.plain20_cifar.pth.tar --lr=0.05 --amc --amc-protocol=mac-constrained --amc-action-range 0.05 0.80 --amc-target-density=0.5 -p=50 --etes=0.3 --gpus=0 --amc-prune-method=stochastic-l1-rank --amc-ft-epochs=1\n",
    "#  time python3 compress_classifier.py --arch=plain20_cifar ../../../data.cifar --lr=0.1 --vs=0 --num-best-scores=5 -p=50 --epochs=60 --gpu=0 --resume=logs/2019.05.13-134220/BEST_adc_episode_477_checkpoint.pth.tar --compress=../automated_deep_compression/fine_tune.yaml\n",
    "fname = fpath.format(\"2019.05.13-134220\") # stochastic L1 (ep=0.1) w/ FT\n",
    "# time python3 compress_classifier.py --arch=plain20_cifar ../../../data.cifar --resume=checkpoint.plain20_cifar.pth.tar --lr=0.05 --amc --amc-protocol=mac-constrained --amc-action-range 0.05 0.80 --amc-target-density=0.5 -p=50 --etes=0.3 --gpus=0 --amc-prune-method=fm-reconstruction --amc-prune-pattern=channels --amc-ft-epochs=0\n",
    "fname = fpath.format(\"2019.05.13-193438\") # stochastic L1 (ep=0.1) w/o FT\n",
    "fname = fpath.format(\"2019.05.22-000039\") # mobilenet; biased gaussian distribution\n",
    "# with action space = {-1, 1}\n",
    "fname = fpath.format(\"mobilenet-gauss-shifted-scaled___2019.05.23-031236/\") # mobilenet; shifted+scaled gaussian distribution\n",
    "fname = fpath.format(\"mobilenet-gauss-shifted-scaled___2019.05.23-235513/\") # SH's DDPG - 375 images\n",
    "fname = fpath.format(\"mobilenet-gauss-shifted-scaled___2019.05.24-015035/\") # SH's DDPG - 3750 images - action 0.05 - 0.8\n",
    "\n",
    "#fname = fpath.format(\"mobilenet-gauss-shifted-scaled___2019.05.24-021003/\") # mobilenet PPO - newest version (better action distribution)\n",
    "\n",
    "fname = fpath.format(\"mobilenet-han-L1___2019.05.25-120749/\") # Failure\n",
    "#fname = fpath.format(\"mobilenet-ddpg-reconstruction___2019.05.25-155416/\") # mobilenet SH's DDPG - my reconstruction\n",
    "fname = fpath.format(\"mobilenet-ddpg-reconstruction___2019.05.27-000814\") # Good! seed=2018\n",
    "\n",
    "fname = fpath.format(\"mobilenet-ddpg-reconstruction___2019.05.27-173606/\") #SH DDPG, \n",
    "\n",
    "# Examples of \"failing\" Coach DDPG\n",
    "#fname = fpath.format(\"mobilenet-ddpg-reconstruction___2019.05.28-061806/\") # Coach DDPG - again (Tab )\n",
    "#fname = fpath.format(\"mobilenet-ddpg-reconstruction___2019.05.28-062438/\") # Coach DDPG - Single GPU (2)\n",
    "\n",
    "fname = fpath.format(\"mobilenet-ddpg-reconstruction___2019.05.28-124524/\") # SH DDPG, better division of dataset?\n",
    "\n",
    "fname = fpath.format(\"mobilenet-ddpg-reconstruction___2019.05.28-202133/\") # \n",
    "fname = fpath.format(\"mobilenet-ddpg-reconstruction___2019.05.28-223402/\") # \n",
    "\n",
    "fname = fpath.format(\"mobilenet-coach-ddpg-reconstruction___2019.05.29-135539/\") \n",
    "# fname = fpath.format(\"mobilenet-ddpg-reconstruction___2019.05.30-021659/\") \n",
    "#fname = fpath.format(\"2019.06.03-015359\")  # Plain 20, 5000 calibration, \n",
    "fname = fpath.format(\"mobilenet-ddpg-reconstruction___2019.06.03-123828/\") # Running Tab 3 - Coach DDPG - MobileNet\n",
    "\n",
    "#fname = fpath.format(\"mobilenet-ddpg-reconstruction___2019.06.03-141214/\") # Tab 7 - Coach DDPG - MobileNet\n",
    "#fname = fpath.format(\"2019.06.03-154857\") # - Sanity test on Plain20\n",
    "#fname = fpath.format(\"2019.06.03-163804\")\n",
    "\n",
    "# fname = fpath.format(\"2019.06.03-213842\") # bottom\n",
    "#fname = fpath.format(\"2019.06.04-115337\") # fixed Coach DDPG\n",
    "\n",
    "\n",
    "#fname = fpath.format(\"2019.06.06-130931\") # Tab 0 - bottom - Plain20 - Group of 8 channels; 20 sampled points\n",
    "fname = fpath.format(\"mobilenet-ddpg-reconstruction___2019.06.09-233457/\") # mobilenet ==> Top1: 56.4%\n",
    "#fname = fpath.format(\"2019.06.10-005424/\") # resnet56; punish_agent  ==> Top1: 90.1%\n",
    "#     fname = fpath.format(\"2019.06.10-005041/\") # plain20\n",
    "#fname = fpath.format(\"2019.06.10-020945\") # resnet56; channels; ==> Top1:90.1\n",
    "#fname = fpath.format(\"2019.06.10-020027\") # plain20 ==> 68.1\n",
    "\n",
    "#fname = fpath.format(\"2019.06.10-112343\") # plain20 ==> 54.6\n",
    "fname = fpath.format(\"mobilenet-ddpg-reconstruction___2019.06.11-235133/\") # MobileNet - Channels - SH DDPG (sanity) \n",
    "#fname = fpath.format(\"plain20_ppo___2019.06.11-233955/\") # Plain 20 - Filter - PPO\n",
    "# DONE fname = fpath.format(\"plain20_ddpg_sh___2019.06.11-234913/\") # Plain20 - Channels - SH DDPG (sanity) \n",
    "fname = fpath.format(\"2019.06.03-081337\") \n",
    "fname = fpath.format(\"2019.06.15-115640/\") \n",
    "\n",
    "#name = fpath.format(\"2019.06.16-161033\") # Done: plain20 - coach - master + BN fixes\n",
    "#fname = fpath.format(\"2019.06.16-161114\") # Done: plain20 - sh\n",
    "#fname = fpath.format(\"2019.06.16-165343\") # Done:    plain20 - coach - master + BN fixes + Sum (instead of concat)\n",
    "fname = fpath.format(\"2019.06.17-112244\") # Tab 3: plain20 - coach - master + BN fixes + Sum (instead of concat) + reward moving-average\n",
    "fname = fpath.format(\"2019.06.17-122227\") # Tab 3\n",
    "fname = fpath.format(\"mobilenet-ddpg-reconstruction___2019.06.17-123221\") # Tab 7 - top: mobilenet group 8 - (now training on tab0, aipg-srv12)\n",
    "fname = fpath.format(\"mobilenet-ddpg-reconstruction___2019.06.17-234704//\") # DONE spining \n",
    "\n",
    "fname = fpath.format(\"mobilenet-ddpg-coach___2019.06.18-015819\") #  coach -mobilenet (OLD)\n",
    "fname = fpath.format(\"mobilenet-ddpg-coach___2019.06.18-145355/\") #  coach -mobilenet\n",
    "fname = fpath.format(\"mobilenet-ddpg-coach___2019.06.18-163029/\") #  coach -mobilenet; additive\n",
    "#fname = fpath.format(\"2019.06.18-171036/\") #  coach -plain20; truncated normal (with slower decay)\n",
    "fname = fpath.format(\"2019.06.18-173633/\") #  coach -plain20; truncated normal after removing the action scaling\n",
    "\n",
    "#fname = fpath.format(\"mobilenet-ddpg-private___2019.06.18-015855\") # private\n",
    "\n",
    "fname = fpath.format(\"mobilenet-ddpg-coach___2019.06.18-211322/\")  # normal noise\n",
    "fname = fpath.format(\"plain20_coach_normal___2019.06.18-211524/\")  # normal noise\n",
    "fname = fpath.format(\"plain20_coach_additive___2019.06.18-211706/\") # additive noise\n",
    "\n",
    "# 200000 buffer size\n",
    "fname = fpath.format(\"mobilenet-ddpg-coach___2019.06.19-003122\")  # normal noise\n",
    "fname = fpath.format(\"plain20_coach_normal___2019.06.19-002948\")  # normal noise\n",
    "fname = fpath.format(\"plain20_coach_additive___2019.06.19-003220\") # additive noise\n",
    "\n",
    "# 2000 buffer size\n",
    "fname = fpath.format(\"mobilenet-ddpg-coach___2019.06.19-014935/\")  # SH - sanity check\n",
    "fname = fpath.format(\"plain20_private_sanity___2019.06.19-015304/\")  # SH - sanity check\n",
    "#fname = fpath.format(\"plain20_coach_normal___2019.06.19-020136/\")  # coach - plain20 - normal noise\n",
    "\n",
    "#fname = fpath.format(\"mnist-ddpg-private___2019.06.19-145723/\")  # MNIST\n",
    "fname = fpath.format(\"plain20_private_sanity___2019.06.20-005611/\") \n",
    "fname = fpath.format(\"plain20_coach___2019.06.20-120705/\")\n",
    "fname = fpath.format(\"resnet20_coach___2019.06.20-144806/\")\n",
    "\n",
    "#fname = fpath.format(\"resnet56-coach___2019.06.20-161432/\")\n",
    "#fname = fpath.format(\"resnet56-private___2019.06.20-161507/\")\n",
    "\n",
    "# Additive\n",
    "fname = fpath.format(\"mobilenet-coach___2019.06.20-221635/\")\n",
    "fname = fpath.format(\"plain20_coach_additive___2019.06.20-221601/\")\n",
    "fname = fpath.format(\"resnet50-coach-private___2019.06.21-021635/\")  # 10 pts\n",
    "#fname = fpath.format(\"resnet50-coach-private___2019.06.21-105717/\") # 30 pts\n",
    "fname = fpath.format(\"resnet50-coach-private___2019.06.21-152735/\") # tab 3 - 10 pts  GOOD\n",
    "\n",
    "#fname = fpath.format(\"mobilenet_coach___2019.06.23-002428\")\n",
    "#fname = fpath.format(\"mobilenet_coach_1000___2019.06.23-154500\")\n",
    "\n",
    "#fname = fpath.format(\"mobilenet_coach___2019.06.23-071645\")\n",
    "#fname = fpath.format(\"mobilenet_coach_1001___2019.06.23-163616\")\n",
    "fname = fpath.format(\"mobilenet_coach_1002___2019.06.24-004134/\")\n",
    "fname = fpath.format(\"mobilenet_coach_1003___2019.06.24-123034/\")\n",
    "\n",
    "# Plain 20\n",
    "fname = fpath.format(\"plain20_coach_1000___2019.06.24-004543\")\n",
    "fname = fpath.format(\"plain20_coach_1001___2019.06.24-122517\")\n",
    "fname2 = fpath.format(\"plain20_coach_1002___2019.06.24-143732\")\n",
    "fname = fpath.format(\"plain20_private_1002___2019.06.25-161018\")\n",
    "\n",
    "#fname = fpath.format(\"plain20_coach_norm_reward_1000___2019.06.25-170941/\")\n",
    "\n",
    "# fname1 = fpath.format(\"plain20_coach_norm_reward_1000___2019.07.03-003825/\")\n",
    "# fname2 = fpath.format(\"plain20_coach_norm_reward_1000___2019.07.03-003834/\")\n",
    "# fname = fname3 = fpath.format(\"plain20_coach_norm_reward_1000___2019.07.02-211806/\")\n",
    "\n",
    "# fname = fname3 = fpath.format(\"mobilenet_coach___2019.07.02-030313/\")\n",
    "# fname = fname3 = fpath.format(\"mobilenet_coach___2019.07.02-112135/\")\n",
    "# fname = fname3 = fpath.format(\"mobilenet_coach___2019.07.02-185420\") # Tab 7\n",
    "# fname = fname3 = fpath.format(\"mobilenet_coach___2019.07.02-191820\") # Tab 3\n",
    "\n",
    "# fname = fname1 = fpath.format(\"mobilenet_new_coach___2019.07.03-010450/\") # Tab 7\n",
    "# fname = fname2 = fpath.format(\"mobilenet_coach___2019.07.03-010359/\") # Tab 3\n",
    "\n",
    "fname = fname1 = fpath.format(\"mobilenet_coach___2019.07.03-024900/\") # Tab 0 - trying 20 pts\n",
    "# fname = fname2 = fpath.format(\"mobilenet_coach___2019.07.03-025343/\") # Tab 0 - trying 30 pts\n",
    "# ==> It's looking like 30 points is helping somewhat, but not sure\n",
    "\n",
    "# Plain 20 baseline (both behave exactly the same; and were logged using the code in the patch working_patched_coach_master_943257a3dd12a4c1ff94ff4ab8e10f2e57c6a207.patch )\n",
    "f_baseline2 = fname4 = fpath.format(\"plain20_coach_norm_reward_1000___2019.07.02-201805\")\n",
    "#f_baseline1 = fname1 = fpath.format(\"plain20_coach_norm_reward_1000___2019.07.02-201808\")\n",
    "\n",
    "# This is new Coach branch (distiller-AMC-induced-changes), without the filter enabled\n",
    "#fname = fname2 = fpath.format(\"plain20_coach_norm_reward_1000___2019.07.03-111647/\") # Tab 3 - plain20 - testing coach\n",
    "\n",
    "# This is new Coach branch (distiller-AMC-induced-changes), __with__ the filter enabled\n",
    "fname = fname3 = fpath.format(\"plain20_coach_norm_reward_1000_use_filter___2019.07.03-115008/\") # Tab 7\n",
    "\n",
    "f_baseline_private = fname2 = fpath.format(\"plain20_private_baseline___2019.07.03-125500/\") # Tab 7 - mobilenet - testing coach\n",
    "#f_baseline_coach_master = fname1 = fpath.format(\"plain20_patched_coach_master_reward_1000___2019.07.03-134423\")\n",
    "\n",
    "#logs/mobilenet_coach___2019.07.02-202456/mobilenet_coach___2019.07.02-202456.log\n",
    "#fname = fname3 = \"../classifier_compression/latest_log_dir/amc.csv\"  # \n",
    "\n",
    "# Trying to see if the problem with coach is only with seed=1000 and deterministic\n",
    "# So went back to the AMC branch, and rand without --deterministic\n",
    "# Tab 7\n",
    "#fname1 = fpath.format(\"plain20_coach_use_filter_not_determinisitic___2019.07.03-143834/\")\n",
    "#fname1 = fpath.format(\"plain20_coach_branch_with_normalization_reward_1001___2019.07.03-185041\")\n",
    "#fname1 = fpath.format(\"plain20_coach_branch_with_normalization_reward_1002___2019.07.03-201254/\")\n",
    "#fname = fpath.format(\"mobilenet_v1_71.2_private_1000___2019.07.03-153014/\")\n",
    "#fname1 = fpath.format(\"mobilenet_v1_71.2_private_1000___2019.07.03-191125/\")\n",
    "\n",
    "# Trying L2-norm\n",
    "fname = fpath.format(\"mobilenet_v1_71.2_private_l2-norm___2019.07.03-214820\")\n",
    "fname = fpath.format(\"mobilenet_v1_71.2_private_l1-norm___2019.07.03-231322\")\n",
    "\n",
    "fname = fpath.format(\"../experiments/plain20-random-l1_rank/2019.07.21-004045/1___2019.07.21-004045\")\n",
    "\n",
    "#fname = fname1 = fpath.format(\"mobilenet_coach___2019.07.03-024900/\") # Tab 0 - trying 20 pts\n",
    "#fname = fname2 = fpath.format(\"mobilenet_coach___2019.07.03-025343/\") # Tab 0 - trying 30 pts\n",
    "\n",
    "#fname = fname1 = fpath.format(\"mobilenet_v1_71.2_private_l1-norm___2019.07.03-231322/\")\n",
    "#fname = fname1 = fpath.format(\"plain20_coach_branch_with_normalization_reward_1001___2019.07.04-012842/\")\n",
    "\n",
    "# This is the coach master + patches\n",
    "#fname = fname2 = fpath.format(\"plain20_coach_branch_with_normalization_reward_1001___2019.07.04-103918\")\n",
    "# This is the baseline\n",
    "#fname1= fpath.format(\"plain20_private_reward_1001___2019.07.04-121236/\")\n",
    "#fname1 = fpath.format(\"plain20_coach_torch1.1___2019.07.04-181433/\")\n",
    "\n",
    "fname = fpath.format(\"plain20_coach_branch_with_normalization_reward_1001___2019.07.24-124001/\")\n",
    "fname = \"../automated_deep_compression/experiments/plain20-ddpg-private-punish/2019.07.29-171102/1___2019.07.29-171111//amc.csv\"\n",
    "#fname = fpath.format(\"../latest_log_dir\")\n",
    "fname = fpath.format(\"mobilenet_coach___2019.07.03-025343\")\n",
    "df = pd.read_csv(fname)\n",
    "df1, df2, df3 = pd.read_csv(fname1), pd.read_csv(fname2), pd.read_csv(fname3)\n",
    "df4 = pd.read_csv(fname4)\n",
    "#df[600:]\n",
    "\n",
    "print(len(df))\n",
    "#net_search_results = df[df[\"ckpt_name\"] == \"BEST_adc_episode_000\"]\n",
    "#net_search_results[\"top1\"].iloc[0]\n",
    "#df[df[\"episode\"] == 0]\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot experiment performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e3963464ce64472ac41cd067f82d81a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(IntSlider(value=10, description='window_size', max=50, step=5), Checkbox(value=True, description='top1'), Checkbox(value=True, description='macs'), Checkbox(value=False, description='params'), Checkbox(value=True, description='reward'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.figure(figsize=(15,7))\n",
    "#print(plt.style.available)\n",
    "#plt.style.use('seaborn-paper')\n",
    "        \n",
    "@interact(window_size=(0,50,5), top1=True, macs=True, params=False, reward=True)\n",
    "def plot_performance_proxy(window_size=10, top1=True, macs=True, params=False, reward=True):\n",
    "    plot_performance(\"Training Data\", df, 0.15, window_size, top1, macs, params, reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df1,df2, df3]\n",
    "df_len = min([len(df) for df in dfs])\n",
    "\n",
    "@interact(window_size=(0,50,5), top1=True, macs=True, params=False, reward=True, zoom=(0,df_len,1))\n",
    "def plot_experiment_comparison(window_size=10, zoom=0):\n",
    "    start = 0\n",
    "    end = zoom if zoom > 0 else 0\n",
    "    plot_performance(\"Compare Experiments (Top1)\", dfs, \n",
    "                     0.15, window_size, True, False, False, False, start, end, plot_type='compare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@interact(window_size=(0,50,5), top1=True, macs=True, params=False, reward=True)\n",
    "def plot_experiment_comparison(window_size=10):\n",
    "    dfs = [df1,df2, df3]\n",
    "    plot_performance(\"Compare Experiments (Top1)\", dfs, \n",
    "                     0.15, window_size, True, False, False, False, plot_type='error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Sample some networks\n",
    "\n",
    "Let's look at the networks with the best top1 accuracy, and see if they share geometrical attributes.\n",
    "\n",
    "We sort the discovered networks by their Top1 accuracy and display the density of each layer in the networks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1_sorted_df = df.sort_values(by=['reward'], ascending=False)\n",
    "top1_sorted_df\n",
    "nrows = 2; ncols = 4\n",
    "f, axarr = plt.subplots(nrows, ncols, figsize=(15,7))\n",
    "for i in range(0, nrows * ncols):\n",
    "    plot_layer_compute_densities(top1_sorted_df, i, ax=axarr[i//ncols, i%ncols], color='g')\n",
    "    # Fine-tune figure; make subplots farther from each other.\n",
    "    f.subplots_adjust(hspace=0.6, wspace=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These are the actions the networks experienced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "top1_sorted_df = df.sort_values(by=['reward'], ascending=False)\n",
    "nrows = 2; ncols = 4\n",
    "f, axarr = plt.subplots(nrows, ncols, figsize=(15,7))\n",
    "for i in range(0, nrows * ncols):\n",
    "    plot_action_history(top1_sorted_df, i, ax=axarr[i//ncols, i%ncols], color='b')\n",
    "    # Fine-tune figure; make subplots farther from each other.\n",
    "    f.subplots_adjust(hspace=0.6, wspace=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per-layer filter density distribution - top 10% networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "top10pct = top1_sorted_df[:int(len(df.index) * 0.1)]\n",
    "#top10pct = df[int(len(df.index) * 0.95):]\n",
    "\n",
    "layer_densities_list = []\n",
    "for index, row in top10pct.iterrows():\n",
    "    layer_densities = json.loads(row['performance'])\n",
    "    layer_densities = list(layer_densities.values())\n",
    "\n",
    "    #net_performance = json.loads(record[\"performance\"])\n",
    "    #ax.bar(range(len(net_performance)), list(net_performance.values()), color=color, align='center')\n",
    "\n",
    "    #layer_densities = [1. - float(sparsity) for sparsity in layer_sparsities]\n",
    "    layer_densities_list.append(layer_densities)\n",
    "\n",
    "layer_densities = np.array(layer_densities_list)\n",
    "mean = layer_densities.mean(axis=0)\n",
    "std = layer_densities.std(axis=0)\n",
    "\n",
    "\n",
    "# Draw the bar diagram of the layer densities\n",
    "fig, ax = plt.subplots(figsize=(15,7.5))\n",
    "ax.set_title(\"Best sampled models (90th percentile)\\nPer-layer filter density (mean and std)\")\n",
    "xpos = [i for i in range(len(mean))]\n",
    "ax.bar(xpos, mean, yerr=std, capsize=10, alpha=0.50, ecolor='black')\n",
    "ax.set_ylabel('Filter density')\n",
    "ax.set_xticks(xpos)\n",
    "layer_names = json.loads(row['performance']).keys()\n",
    "ax.set_xticklabels(layer_names, rotation=270)\n",
    "ax.yaxis.grid(True)\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network 2D embeddings\n",
    "\n",
    "Let's create an embedding of the networks AMC discovers over the course of each experiment session.  Each network is projected onto a 2D plane mapping the Top1 accuracy versus the compute budget, and is represented by a small circle. I used gradient-color-coding to show the relative phase where each network is discovered.  Lighter circles are networks discovered early in the search, darker networks are discovered later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "top1 = df['top1']\n",
    "normalized_macs = df['normalized_macs']\n",
    "plot_2d_embeddings(top1, normalized_macs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = AnimatedScatter(normalized_macs, top1)\n",
    "plt.title('Projection of Discovered Networks ({})'.format(len(top1)))  \n",
    "plt.xlabel('Normalized MACs')\n",
    "plt.ylabel('Top1 Accuracy')\n",
    "#a.ani.save('amc_vgg16.mp4', fps=10, dpi=80) #Frame per second controls speed, dpi controls the quality \n",
    "rc('animation', html='html5')\n",
    "a.ani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a histogram of the actions\n",
    "\n",
    "We want to look at the distribution of the sampled agent actions (```agent_actions``` below), to make sure they are not skewed or biased.\n",
    "\n",
    "We also want to compare these actions to the actions the environment actually acts on (these we call ```env_actions``` below).  The natural PPO action-space is (-inf, inf) so the environment needs to scale and shift the agent actions to fit into the \"real\" action-space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_actions(df, action_type='action_history'):\n",
    "    actions = []\n",
    "    for index, record in df.iterrows():\n",
    "        #layer_sparsities = record[action_type]\n",
    "        #layer_sparsities = layer_sparsities[1:-1].split(\",\")\n",
    "        layer_sparsities = json.loads(record[action_type])\n",
    "        layer_sparsities = [float(sparsity) for sparsity in layer_sparsities]\n",
    "        actions.extend(layer_sparsities)\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_actions = get_all_actions(df, action_type='agent_action_history')\n",
    "env_actions = get_all_actions(df, action_type='action_history')\n",
    "print(len(agent_actions))\n",
    "\n",
    "plt.figure(figsize=[15,7.5])\n",
    "plt.hist(agent_actions, histtype='step', bins=100, label='agent_actions (u={:.2f} std={:.2f})'.format(\n",
    "                                                                                        np.mean(agent_actions),\n",
    "                                                                                        np.std(agent_actions)));\n",
    "plt.hist(env_actions, histtype='step', bins=100, label='env_actions (u={:.2f} std={:.2f})'.format(\n",
    "                                                                                        np.mean(env_actions),\n",
    "                                                                                        np.std(env_actions)));\n",
    "\n",
    "plt.title('Action histogram (actions as seen by the environment)')\n",
    "plt.legend()\n",
    "plt.xlabel('Action value')\n",
    "plt.ylabel('Frequency');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
